

1.
https://github.com/jemalloc/jemalloc

2.
./autogen.sh --with-jemalloc-prefix=je_ --disable-valgrind
make CC=gcc


realloc
原型是extern void *realloc(void *mem_address, unsigned int newsize);
指针名=（数据类型*）realloc（要改变内存大小的指针名，新的大小）。
新的大小可大可小（如果新的大小大于原内存大小，则新分配部分不会被初始化；如果新的大小小于原内存大小，可能会导致数据丢失[1-2]）
头文件#include <stdlib.h> 有些编译器需要#include <malloc.h>，在TC2.0中可以使用alloc.h头文件
功能
先判断当前的指针是否有足够的连续空间，如果有，扩大mem_address指向的地址，并且将mem_address返回，
如果空间不够，先按照newsize指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来mem_address所指内存区域
（注意：原来指针是自动释放，不需要使用free），同时返回新分配的内存区域的首地址。即重新分配存储器块的地址。
返回值
如果重新分配成功则返回指向被分配内存的指针，否则返回空指针NULL。


函数原型：void *calloc(size_t n, size_t size)；
功 能： 在内存的动态存储区中分配n个长度为size的连续空间，函数返回一个指向分配起始地址的指针；如果分配不成功，返回NULL。


函数：void * memalign (size_t boundary, size_t size) 

函数memalign将分配一个由size指定大小，地址是boundary的倍数的内存块。参数boundary必须是2的幂！
函数memalign可以分配较大的内存块，并且可以为返回的地址指定粒度。






jemalloc是freebsd的内存分配算法

1：arena:把内存分成许多不同的小块来分而治之，该小块便是arena,让我们想象一下，给几个小朋友一张大图纸，让他们随意地画点。
结果可想而知，他们肯定相互顾忌对方而不敢肆意地画（synchronization），从而影响画图效率。但是如果老师事先在大图纸上划分好
每个人的区域，小朋友们就可以又快又准地在各自地领域上画图。这样的概念就是arena。它是jemalloc的核心分配管理区域，对于多核
系统，会默认分配4*cores个arena 。线程采用轮询的方式来选择响应的arena进行内存分配。

2: chunk。具体进行内存分配的区域，默认大小是4M，chunk以page为单位进行管理，每个chunk的前6个page用于存储后面page的状态，
比如是否分配或已经分配

3：bin:用来管理各个不同大小单元的分配，比如最小的Bin管理的是8字节的分配，每个Bin管理的大小都不一样，依次递增。

4：run:每个bin在实际上是通过对它对应的正在运行的Run进行操作来进行分配的，一个run实际上就是chunk里的一块区域，大小是page
的整数倍，具体由实际的bin来决定，比如8字节的bin对应的run就只有1个page，可以从里面选取一个8字节的块进行分配。在run的最开
头会存储着这个run的信息，比如还有多少个块可供分配。

5：tcache。线程对应的私有缓存空间，默认是使用的。因此在分配内存时首先从tcache中找，miss的情况下才会进入一般的分配流程。

arena和bin的关系：每个arena有个bin数组，每个bin管理不同大小的内存（run通过它的配置去获取相应大小的内存），每个tcahe有一
个对应的arena，它本身也有一个bin数组（称为tbin），前面的部分与arena的bin数组是对应的，但它长度更大一些，因为它会缓存一些
更大的块；而且它也没有对应的run的概念

chunk与run的关系：chunk默认是4M，而run是在chunk中进行实际分配的操作对象，每次有新的分配请求时一旦tcache无法满足要求，就要
通过run进行操作，如果没有对应的run存在就要新建一个，哪怕只分配一个块，比如只申请一个8字节的块，也会生成一个大小为一个page
（默认4K）的run；再申请一个16字节的块，又会生成一个大小为4096字节的run。run的具体大小由它对应的bin决定，但一定是page的整数
倍。因此实际上每个chunk就被分成了一个个的run。


内存分配的，具体流程如下：

       1.   如果请求size不大于arena的最小的bin（笔者机器上是3584字节），那么就通过线程对应的tcache来进行分配。首先确定size
	   的大小属于哪一个tbin，比如2字节的size就属于最小的8字节的tbin，然后查找tbin中有没有缓存的空间，如果有就进行分配，没有
	   则为这个tbin对应的arena的bin分配一个run，然后把这个run里面的部分块的地址依次赋给tcache的对应的bin的avail数组，相当于
	   缓存了一部分的8字节的块，最后从这个availl数组中选取一个地址进行分配；
       2.   如果请求size大于arena的最小的bin，同时不大于tcache能缓存的最大块（笔者机器上是32K），也会通过线程对应的tcache来
	   进行分配，但方式不同。首先看tcache对应的tbin里有没有缓存块，如果有就分配，没有就从chunk里直接找一块相应的page整数倍大
	   小的空间进行分配（当这块空间后续释放时，这会进入相应的tcache对应的tbin里）；
       3.   如果请求size大于tcache能缓存的最大块，同时不大于chunk大小（默认是4M），具体分配和第2类请求相同，区别只是没有使
	   用tcache；
       4.   如果请求大于chunk大小，直接通过mmap进行分配。
 
回收流程大体和分配流程类似，有tcache机制的会将回收的块进行缓存，没有tcache机制的直接回收（不大于chunk的将对应的page状态进行
修改，回收对应的run；大于chunk的直接munmap）。需要关注的是jemalloc何时会将内存还给操作系统，因为ptmalloc中存在因为使用top_chunk
机制（详见华庭的文章）而使得内存无法还给操作系统的问题。目前看来，除了大内存直接munmap，jemalloc还有两种机制可以释放内存：
       1.   当释放时发现某个chunk的所有内存都已经为脏（即分配后又回收）就把整个chunk释放；
       2.   当arena中的page分配情况满足一个阈值时对dirty page进行purge（通过调用madvise来进行）。这个阈值的具体含义是该arena中
	   的dirty page大小已经达到一个chunk的大小且占到了active page的1/opt_lg_dirty_mult（默认为1/32）。active page的意思是已经
	   正在使用中的run的page，而dirty page就是其中已经分配后又回收的page。





